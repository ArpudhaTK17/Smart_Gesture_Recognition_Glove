# Smart_Gesture_Recognition_Glove
Communication challenges experienced by people
with hearing and speech impairments tend to restrict their
conversations and communications to people who understand
sign language. This tends to create a wide societal gap between
normal people and specially abled people. This article introduces
a Smart Gesture Recognition Glove intended to interpret sign
language into letters, promoting greater accessibility and easier
communication across a wider range of applications. The system
combines ESP32 microcontrollers, flex sensors, and an MPU6050
inertial measurement unit for hand movement detection. The
sensor readings are analyzed with a trained machine-learning
model that can accurately classify dynamic and static gestures.
These identified gestures are rendered on an LCD display in
real-time. This low-cost, handheld alternative is both accurate
and responsive, and seeks to fill the communication gap for
those who use sign language. It is also a dynamic and useful
system which can also be utilized in situations where speech
and hearing are impaired due to external or environmental
factors. Experimental outcomes show the systemâ€™s robustness and
prospects for deployment in everyday life.
